<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Cui Chi</title><meta name="author" content="Cui Chi"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 5.4.2"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Cui Chi</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/blogs"> Blog</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/profile.png" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Cui Chi</h3><p class="author-bio">Master student in NUS</p></div><div class="author-links"><button class="btn m-social-links">Links</button></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detail CV.</span></i></a><a target="_blank" rel="noopener" href="https://clustrmaps.com/site/1bvca"><img src="//clustrmaps.com/map_v2.png?cl=ffffff&amp;w=a&amp;t=tt&amp;d=1-ZWvsyA2_8iEeKv0taNJbg0D67qsg-52quih6hCUC8" style="display: none"></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">A Summary of PlotSteal</h2><article><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.11982">Paper</a></p>
<p>This article presents a novel side channel attack strategy for extracting data from machine learning models, such as the model type, optimization algorithm, and batch size, leveraging scientific plots like t-SNE and Loss plots</p>
<p>The intuition behind this attack is that scientific plots, such as t-SNE plots and loss plots, which are used to demonstrate the performance of machine learning models, contain valuable information about the model’s architecture and hyperparameters. These plots are often easily accessible, for example, through research papers or project websites, and thus provide a potential side channel for an attacker to exploit.</p>
<p><strong>Attack Strategy:</strong> The basic idea of the attack is training an “attack model” to recognize these scientific plots and infer the target model’s information. The attack model is essentially an image classifier that is trained on a dataset of scientific plots generated by “shadow models” that mimic the target model. Once trained, the attack model can then analyze a scientific plot from the target model and infer its architecture and hyperparameters.The process unfolds in three steps: Firstly, the attacker randomly selects information to generate a variety of shadow models. Secondly, they create scientific plots for each shadow model. Lastly, these plots, alongside model information, serve as inputs to train an attack model, which is essentially an image classifier.</p>
<p><strong>Evaluation:</strong> In evaluation, this paper demonstrated the effectiveness of the attack in inferring model information from t-SNE plots and loss plots, respectively. All of experiments were conducted using three benchmark datasets: CIFAR-10, FashionMNIST, and SVHN. For each dataset, 2250 shadow models and 750 target models were trained.</p>
<p><strong>Evaluation on t-SNE Plots:</strong> For t-SNE plots, the results demonstrate that the proposed technique successfully infers model information, particularly the optimization algorithm, using t-SNE plots. It can also accurately predict activation functions, the number of fully connected layers, and convolutional layers in custom model architectures.</p>
<p>Following this, the ablation study reveals that the attack remains effective even with a limited number of shadow models and is not significantly impacted by the color, density, and perplexity of the t-SNE plots. It still extracts model data even from plots with varying data distributions and settings. When compared to query-based attacks, this approach matches, especially when target model query output is limited. It also bolsters adversarial model creation by identifying similar shadow models.</p>
<p>The evaluation also considered various defense strategies. The two most effective methods discovered involve thresholding embedding values and introducing Gaussian noise into the coordinates of the t-SNE points. However, these defenses could still be bypassed by adaptive attacks.</p>
<p><strong>Evaluation on Loss Plots:</strong> For loss plots, the attack performance generally outperforms that on t-SNE plots. A comparison of loss plots with and without axes shows that the loss curve itself is instrumental in enabling the attack model to identify model types. Additionally, three defensive strategies are tested, with TensorBoard and sliding window proving to be effective. However, these strategies also fail in the presence of an adaptive attacker.</p>
<p><strong>Analysis of Grad-CAM:</strong> The authors leverage Grad-CAM to understand why scientific plots can infer model information. The findings suggest that the shape of the t-SNE plots and the first 10 timestamps of the loss plots most significantly impact the original model’s performance, indicating potential data leakage.</p>
<p><strong>Limitations:</strong> The approach assumes knowledge of the training dataset distribution, , which is unreasonable because the adversary lacks information about both the model and dataset in practice. Performance significantly decreases if shadow models and target models are trained with different datasets i.e., evaluating on a more general assumption. Hence, without knowledge of the target model’s training dataset, the attack strategy becomes significantly challenging.</p>
<p><strong>Conclusion:</strong> In summary, the article introduces a unique technique for using scientific plots to reveal information about target models, offering a non-interactive means of model data theft. The authors use plenty of experiments to show us the method is effective on various suituations as well as comparable with query-based attacks. However, its practical application is constrained by the requirement for adversaries to know the training dataset’s distribution. Consequently, for industry models where both the architecture and dataset are private, this approach falls short.</p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/blogs"> Blog</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_site_pv">Hits: <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></span><div class="copyright">&copy;2020 - 2023 by Cui Chi</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" async>$(document).on({
  'pjax:complete': function() {
    $.ajax({
      type: "GET",
      url: "https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-MML-AM_CHTML",
      dataType: "script",
      cache: true,
      success: function() {
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
        var math = document.getElementsByClassName("entry-content")[0];
        MathJax.Hub.Queue(["Typeset",MathJax.Hub,math]);
      },
    });
  }
});</script></body></html>